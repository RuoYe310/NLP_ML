{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jieba\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77f710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import jieba\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5898327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    \"\"\"\n",
    "    读取原始数据，分词，返回titles、labels\n",
    "    \"\"\"\n",
    "    titles, labels = [], []\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        print('current file:', data_path)\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            _, _, label, title, _ = line.split('_!_')\n",
    "            words = ' '.join(jieba.cut(title))  # 分词\n",
    "            titles.append(words), labels.append(label)\n",
    "        print(data_path, 'finish')\n",
    "    return titles, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed4ab893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(feature_num=10000):\n",
    "    \"\"\"分词，使用词袋法、获得tf-idf特征\"\"\"\n",
    "    # 读取train dev test数据\n",
    "    path = os.getcwd()\n",
    "    train_path = os.path.join(path,\"data\\\\toutiao_cat_data.train.txt\")\n",
    "    dev_path = os.path.join(path,\"data\\\\toutiao_cat_data.dev.txt\")\n",
    "    test_path = os.path.join(path,\"data\\\\toutiao_cat_data.test.txt\")\n",
    "    (train_titles, train_labels), (dev_titles, dev_labels), (test_titles, test_labels) = \\\n",
    "        read_data(train_path), read_data(dev_path), read_data(test_path)\n",
    "\n",
    "    # 设置TfidfVectorizer，并训练\n",
    "    vectorizer = TfidfVectorizer(max_features=feature_num)  # 设定max_features，保留词频最高的feature_num个词\n",
    "    vectorizer.fit(train_titles)  # 输入训练集分词结果，通过fit方法拟合vectorizer\n",
    "\n",
    "    # 打印前后100个特征词\n",
    "    print('head 100 words:', ' '.join(vectorizer.get_feature_names_out()[:100]))\n",
    "    print('tail 100 words:', ' '.join(vectorizer.get_feature_names_out()[-100:]))\n",
    "\n",
    "    # 转换titles为tfidf矩阵\n",
    "    # 通过transform方法将分好词的text转化为tfidf的float矩阵\n",
    "    train_X, dev_X, test_X = \\\n",
    "        vectorizer.transform(train_titles), vectorizer.transform(dev_titles), vectorizer.transform(test_titles)\n",
    "    print('shape:', train_X.shape, dev_X.shape, test_X.shape)\n",
    "\n",
    "    return train_X, train_labels, dev_X, dev_labels, test_X, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d25d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest():\n",
    "    \"\"\"训练随机森林分类器\"\"\"\n",
    "    train_X, train_labels, dev_X, dev_labels, test_X, test_labels = get_features(feature_num=10000)\n",
    "\n",
    "    # 为RF设置参数，并训练\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=100,  # 设置森林里决策树的个数为100个\n",
    "        criterion='gini',  # 设置使用基尼指数决定划分属性\n",
    "        max_depth=200,  # 树的最大深度，None为不限制树深，控制模型拟合程度\n",
    "        max_features='sqrt',  # 每次选择最优时，考虑的最大特征数，即sqrt(n_features)\n",
    "        bootstrap=True,  # 使用自助采样，获得样本子集\n",
    "        class_weight='balanced',  # 平衡根据类别频率，平衡权重\n",
    "        random_state=0,  # 设置随机种子，可复现的随机\n",
    "        n_jobs=-1,  # 启用所有cpu，并行训练\n",
    "    )\n",
    "    init_time = time.time()\n",
    "    clf.fit(train_X, train_labels)\n",
    "    print('train rf finish, cost time: {}s'.format(time.time() - init_time))\n",
    "\n",
    "    # 评估train acc、dev acc、test acc\n",
    "    train_acc = clf.score(train_X, train_labels)\n",
    "    dev_acc = clf.score(dev_X, dev_labels)\n",
    "    test_acc = clf.score(test_X, test_labels)\n",
    "    print('train acc:', train_acc)\n",
    "    print('dev acc:', dev_acc)\n",
    "    print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97d81cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gbdt():\n",
    "    \"\"\"训练gbdt模型\"\"\"\n",
    "    train_X, train_labels, dev_X, dev_labels, test_X, test_labels = get_features(feature_num=10000)\n",
    "\n",
    "    # 为GBDT设置参数，并训练\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=100,  # 设置森林里决策树的个数为100个\n",
    "        learning_rate=0.1,  # 学习率\n",
    "        loss='log_loss',  # 损失函数，deviance即偏差、残差\n",
    "        subsample=1.0,  # 训练个体学习器时，可以允许采样的百分比（类似bagging算法，带来样本的扰动），默认为1.0，表示不采样\n",
    "        max_depth=100,  # 设置最大树深\n",
    "    )\n",
    "    init_time = time.time()\n",
    "    clf.fit(train_X, train_labels)\n",
    "    print('train gbdt finish, cost time: {}s'.format(time.time() - init_time))\n",
    "\n",
    "    # 评估train acc、dev acc、test acc\n",
    "    train_acc = clf.score(train_X, train_labels)\n",
    "    dev_acc = clf.score(dev_X, dev_labels)\n",
    "    test_acc = clf.score(test_X, test_labels)\n",
    "    print('train acc:', train_acc)\n",
    "    print('dev acc:', dev_acc)\n",
    "    print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e781d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost():\n",
    "    \"\"\"训练xgb\"\"\"\n",
    "    train_X, train_labels, dev_X, dev_labels, test_X, test_labels = get_features(feature_num=10000)\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=100,  # 设置森林决策树为100棵\n",
    "        learning_rate=0.1,  # 学习率\n",
    "        booster='gbtree',  # 个体学习器类型为gbtree，即CART决策树\n",
    "        objective='multi:softmax',  # 目标，多分类softmax\n",
    "        max_depth=100,  # 设置最大树深为100\n",
    "        subsample=1.0,  # 训练个体学习器时，可以允许采样的百分比（类似bagging算法，带来样本的扰动），默认为1.0，表示不采样\n",
    "        reg_lambda=1,  # l2正则化系数，与正则化强度成正比（与lr svm的C互为倒数）\n",
    "        random_state=0,  # 固定随机种子\n",
    "        n_jobs=-1,  # 启用所有cpu，并行训练\n",
    "    )\n",
    "    init_time = time.time()\n",
    "    clf.fit(train_X, train_labels)\n",
    "    print('train xgboost finish, cost time: {}s'.format(time.time() - init_time))\n",
    "\n",
    "    # 评估train acc、dev acc、test acc\n",
    "    train_acc = clf.score(train_X, train_labels)\n",
    "    dev_acc = clf.score(dev_X, dev_labels)\n",
    "    test_acc = clf.score(test_X, test_labels)\n",
    "    print('train acc:', train_acc)\n",
    "    print('dev acc:', dev_acc)\n",
    "    print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79dfb6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost():\n",
    "    \"\"\"训练xgb\"\"\"\n",
    "    train_X, train_labels, dev_X, dev_labels, test_X, test_labels = get_features(feature_num=10000)\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=100,  # 设置森林决策树为100棵\n",
    "        learning_rate=0.1,  # 学习率\n",
    "        booster='gbtree',  # 个体学习器类型为gbtree，即CART决策树\n",
    "        objective='multi:softmax',  # 目标，多分类softmax\n",
    "        max_depth=100,  # 设置最大树深为100\n",
    "        subsample=1.0,  # 训练个体学习器时，可以允许采样的百分比（类似bagging算法，带来样本的扰动），默认为1.0，表示不采样\n",
    "        reg_lambda=1,  # l2正则化系数，与正则化强度成正比（与lr svm的C互为倒数）\n",
    "        random_state=0,  # 固定随机种子\n",
    "        n_jobs=-1,  # 启用所有cpu，并行训练\n",
    "    )\n",
    "    init_time = time.time()\n",
    "    clf.fit(train_X, train_labels)\n",
    "    print('train xgboost finish, cost time: {}s'.format(time.time() - init_time))\n",
    "\n",
    "    # 评估train acc、dev acc、test acc\n",
    "    train_acc = clf.score(train_X, train_labels)\n",
    "    dev_acc = clf.score(dev_X, dev_labels)\n",
    "    test_acc = clf.score(test_X, test_labels)\n",
    "    print('train acc:', train_acc)\n",
    "    print('dev acc:', dev_acc)\n",
    "    print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94594c41",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current file: data/toutiao_cat_data.train.txt\n",
      "data/toutiao_cat_data.train.txt finish\n",
      "current file: data/toutiao_cat_data.dev.txt\n",
      "data/toutiao_cat_data.dev.txt finish\n",
      "current file: data/toutiao_cat_data.test.txt\n",
      "data/toutiao_cat_data.test.txt finish\n",
      "head 100 words: 00 01 02 03 04 05 052d 055 06 07 08 09 10 100 1000 10000 101 102 103 104 108 11 110 112 12 120 1200 125 128 13 130 1300 14 140 15 150 1500 16 160 1600 1688 17 170 18 180 180508 180509 180512 19 1945 20 200 2000 2008 2013 2014 2015 2016 2017 2018 2019 2020 2022 2024 2025 21 211 22 23 24 240 25 250 2500 26 27 28 29 30 300 3000 31 318 32 3200 33 34 35 350 3500 36 360 365 37 38 39 3d 40 400 4000\n",
      "tail 100 words: 高盛 高科技 高空 高端 高管 高级 高考 高考状元 高能 高薪 高调 高质量 高贵 高超音速 高跟鞋 高达 高送 高通 高速 高速公路 高配 高铁 高颜值 高龄 鬼子 鬼才 魅力 魅族 魔兽 魔咒 魔王 魔鬼 鱼雷 鲁班 鲁能 鲁迅 鲜为人知 鲜肉 鲜花 鲨鱼 鸟巢 鸡蛋 鸦鹊 鸿雁 鸿鹄 鹈鹕 鹿岛 鹿晗 鹿角 麒麟 麦凯恩 麦迪 麻将 麻烦 麻辣 黄圣 黄圣依 黄子 黄家驹 黄山 黄晓明 黄景 黄河 黄海 黄渤 黄瓜 黄磊 黄紫昌 黄花 黄金 黎巴嫩 黎明 黑人 黑名单 黑客 黑帮 黑幕 黑暗 黑白 黑色 黑马 黑龙江 黑龙江省 默克尔 默默 鼓励 鼓掌 鼠标 鼻子 鼻祖 齐发 齐名 齐聚 齐达内 龙头 龙头股 龙岩 龙湖 龙虎榜 龙虾\n",
      "shape: (362688, 10000) (10000, 10000) (10000, 10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:310: FutureWarning: The loss parameter name 'deviance' was deprecated in v1.1 and will be removed in version 1.3. Use the new parameter name 'log_loss' which is equivalent.\n",
      "  warnings.warn(\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-951859149f11>\", line 1, in <module>\n",
      "    train_gbdt()\n",
      "  File \"<ipython-input-8-207848546f24>\", line 14, in train_gbdt\n",
      "    clf.fit(train_X, train_labels)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 668, in fit\n",
      "    n_stages = self._fit_stages(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 745, in _fit_stages\n",
      "    raw_predictions = self._fit_stage(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 247, in _fit_stage\n",
      "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1342, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 458, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\Anaconda\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\Anaconda\\lib\\inspect.py\", line 1477, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"D:\\Anaconda\\lib\\linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"D:\\Anaconda\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"D:\\Anaconda\\lib\\tokenize.py\", line 394, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"D:\\Anaconda\\lib\\tokenize.py\", line 363, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"D:\\Anaconda\\lib\\tokenize.py\", line 321, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-951859149f11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_gbdt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-207848546f24>\u001b[0m in \u001b[0;36mtrain_gbdt\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0minit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train gbdt finish, cost time: {}s'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0minit_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    669\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    744\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    746\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1343\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2060\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "train_gbdt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258514b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for PyTorch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
